import os, json, textwrap, datetime, requests, bs4, pandas as pd, warnings
import streamlit as st
from newspaper import Article
from duckduckgo_search import DDGS
import openai

# â”€â”€â”€ ç’°å¢ƒè¨­å®š â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
warnings.filterwarnings("ignore", category=SyntaxWarning)
openai.api_key = st.secrets["OPENAI_API_KEY"]

PRIMARY_MODEL   = "gpt-4o-mini"     # 4o ãŒä½¿ãˆãªã„å ´åˆã¯è‡ªå‹•ã§ fallback
FALLBACK_MODEL  = "gpt-3.5-turbo"

st.set_page_config(page_title="SQEG ã‚¯ã‚¤ãƒƒã‚¯ãƒã‚§ãƒƒã‚«ãƒ¼", page_icon="ğŸ”")
st.title("ğŸ” SQEG 2025-01 ç°¡æ˜“è©•ä¾¡ãƒ„ãƒ¼ãƒ«ï¼ˆJina API å¯¾å¿œï¼‰")

# â”€â”€â”€ æœ¬æ–‡å–å¾— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def fetch(src: str):
    """URLâ†’ newspaper3k â†’ requests+BS4 â†’ Jina AI ã® 3 æ®µéšã§æœ¬æ–‡æŠ½å‡º"""
    ua = {"User-Agent": "Mozilla/5.0"}
    if src.startswith("http"):
        # â‘  newspaper3k
        try:
            art = Article(src, language="ja")
            art.download(); art.parse()
            return art.title or "", art.text
        except Exception:
            pass

        # â‘¡ requests + BeautifulSoup
        try:
            html = requests.get(src, timeout=10, headers=ua).text
            soup = bs4.BeautifulSoup(html, "html.parser")
            title = soup.title.string.strip() if soup.title else ""
            body  = "\n".join(p.get_text(" ", strip=True) for p in soup.find_all("p"))
            if body.strip():
                return title, body[:20000]
        except Exception:
            pass

        # â‘¢ Jina AI Readability API
        try:
            api = "https://r.jina.ai/http://" + src.lstrip("https://").lstrip("http://")
            jres = requests.get(api, timeout=10, headers=ua).json()
            title = jres.get("title", "").strip()
            body  = jres.get("content", "").strip()
            return title, body[:20000]
        except Exception:
            return "", ""

    # ç›´æ¥æœ¬æ–‡
    return "", src

# â”€â”€â”€ é¡ä¼¼ãƒšãƒ¼ã‚¸å€™è£œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def search_ddg(query: str, k: int = 5):
    q = query[:100]
    try:
        with DDGS() as ddgs:
            return [f"{r['title']} â€” {r['body']}" for r in ddgs.text(q, max_results=k)]
    except Exception:
        return []

# â”€â”€â”€ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PROMPT = """
ã‚ãªãŸã¯ Google Search Quality Evaluator ã§ã™ã€‚
è¨˜äº‹æœ¬æ–‡ã¨é¡ä¼¼ãƒšãƒ¼ã‚¸å€™è£œã‚’æ¸¡ã—ã¾ã™ã€‚
SQEG 2025-01 ã«å¾“ã„ã€æ—¥æœ¬èªã§æ¬¡ã® JSON ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚

{
  "pq":"Lowest|Low|Medium|High|Highest",
  "nm":"Fails|Slightly|Moderately|Highly|Fully",
  "effort":0-5,"originality":0-5,"duplication_rate":0-100,
  "skill":0-5,"accuracy":0-5,
  "eeat_summary":"<100å­—ä»¥å†…>",
  "improvement_advice":"<200å­—ä»¥å†…>"
}

å¿…ãš JSON ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""

# â”€â”€â”€ UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
src = st.text_area("URL ã¾ãŸã¯æœ¬æ–‡ã‚’å…¥åŠ›ã—ã¦ã€è©•ä¾¡ã™ã‚‹ã€ã‚’æŠ¼ã—ã¦ãã ã•ã„", height=200)
if st.button("è©•ä¾¡ã™ã‚‹") and src.strip():
    with st.spinner("è©•ä¾¡ä¸­â€¦"):
        title, body = fetch(src.strip())
        if not body:
            st.error("âŒ è¨˜äº‹æœ¬æ–‡ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚URL ã§ãªãæœ¬æ–‡ã‚’ç›´æ¥è²¼ã£ã¦è©¦ã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        query = title or " ".join(body.split()[:15])
        user_content = (
            "###æœ¬æ–‡\n"
            + textwrap.shorten(body, width=12000, placeholder='...[cut]...')
            + "\n\n###é¡ä¼¼\n"
            + "\n".join(search_ddg(query))
        )

        def call_llm(model):
            return openai.ChatCompletion.create(
                model=model, temperature=0.1,
                messages=[{"role":"system","content":PROMPT},
                          {"role":"user","content":user_content}]
            )

        try:
            chat = call_llm(PRIMARY_MODEL)
        except Exception:
            chat = call_llm(FALLBACK_MODEL)

        raw = chat.choices[0].message.content.strip()
        if raw.startswith("```"):
            raw = raw.split("```")[1]

        try:
            data = json.loads(raw)
        except json.JSONDecodeError:
            st.error("âŒ JSON ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            st.write("å—ä¿¡å†…å®¹:", raw)
            st.stop()

    # â”€â”€â”€ æ—¥æœ¬èªãƒ©ãƒ™ãƒ«å¤‰æ› â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    label = {
        "pq":"ãƒšãƒ¼ã‚¸å“è³ª (PQ)","nm":"ãƒ‹ãƒ¼ã‚ºå……è¶³åº¦ (NM)",
        "effort":"åŠ´åŠ›","originality":"ç‹¬è‡ªæ€§","duplication_rate":"é‡è¤‡ç‡ (%)",
        "skill":"ã‚¹ã‚­ãƒ«/æŠ€å·§","accuracy":"æ­£ç¢ºæ€§",
        "eeat_summary":"E-E-A-T è¦ç´„","improvement_advice":"æ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹"
    }
    st.subheader("è©•ä¾¡çµæœ")
    st.json({label[k]:v for k,v in data.items()}, expanded=False)

    if data["pq"] in ["Lowest","Low"]:
        st.error("âš ï¸ ãƒšãƒ¼ã‚¸å“è³ªãŒä½è©•ä¾¡ã§ã™ã€‚ãƒªãƒ©ã‚¤ãƒˆã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")

    # â”€â”€â”€ CSV ãƒ­ã‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    pd.DataFrame([{
        "timestamp": datetime.datetime.now().isoformat(timespec="seconds"),
        "source": src[:100], **data
    }]).to_csv("sqeg_log.csv", mode="a", index=False, header=not os.path.exists("sqeg_log.csv"))
    st.success("çµæœã‚’ sqeg_log.csv ã«è¿½è¨˜ã—ã¾ã—ãŸ âœ…")
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
