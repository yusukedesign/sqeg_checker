import os, json, textwrap, datetime, pandas as pd, streamlit as st
from newspaper import Article
from duckduckgo_search import DDGS
import openai

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OpenAI APIã‚­ãƒ¼ã¯ .streamlit/secrets.toml ã«æ›¸ã„ã¦ãã ã•ã„
#   OPENAI_API_KEY = "sk-xxxxxxxx"
# Streamlit Cloud ã§ã¯ã€ŒSecretsã€ã‚¿ãƒ–ã«åŒã˜ã‚­ãƒ¼ã‚’ç™»éŒ²
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
openai.api_key = st.secrets["OPENAI_API_KEY"]

st.set_page_config(page_title="SQEG ã‚¯ã‚¤ãƒƒã‚¯ãƒã‚§ãƒƒã‚«ãƒ¼", page_icon="ğŸ”", layout="centered")
st.title("ğŸ” SQEG 2025-01 ç°¡æ˜“è©•ä¾¡ãƒ„ãƒ¼ãƒ«")

src = st.text_area("URL ã¾ãŸã¯æœ¬æ–‡ã‚’å…¥åŠ›ã—ã€ä¸‹ã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãã ã•ã„", height=200)
if st.button("è©•ä¾¡ã™ã‚‹"):

    # â”€â”€â”€ 1. URLãªã‚‰æœ¬æ–‡æŠ½å‡º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def fetch(text_or_url: str):
        if text_or_url.startswith("http"):
            art = Article(text_or_url, language="ja")
            art.download(); art.parse()
            return art.title or "", art.text
        return "", text_or_url

    title, body = fetch(src.strip())
    if not body:
        st.error("æœ¬æ–‡ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚URL/ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # â”€â”€â”€ 2. DuckDuckGoã§é¡ä¼¼ã‚¿ã‚¤ãƒˆãƒ«å–å¾—ï¼ˆã‚³ãƒ”ãƒ¼ç–‘æƒ‘ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰ â”€â”€â”€
    def search_ddg(query: str, k: int = 5):
        out = []
        with DDGS() as ddgs:
            for r in ddgs.text(query, max_results=k):
                out.append(f"{r['title']} â€” {r['body']}")
        return out

    query = title if title else " ".join(body.split()[:15])
    similar_snips = search_ddg(query)

    # â”€â”€â”€ 3. LLM ã¸è©•ä¾¡ä¾é ¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    SYSTEM_PROMPT = """
ã‚ãªãŸã¯ Google Search Quality Evaluator ã§ã™ã€‚
è¨˜äº‹æœ¬æ–‡ã¨ã‚¦ã‚§ãƒ–æ¤œç´¢ã§å¾—ãŸé¡ä¼¼ãƒšãƒ¼ã‚¸å€™è£œã‚’æ¸¡ã—ã¾ã™ã€‚
SQEG 2025-01 (3.2 / 4.6.6 / 5.2.1 / 7.1) ã«å¾“ã„æ¡ç‚¹ã—ã€æ¬¡ã®JSONã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

{
  "pq": "Lowest|Low|Medium|High|Highest",
  "nm": "Fails|Slightly|Moderately|Highly|Fully",
  "effort": 0-5,
  "originality": 0-5,
  "duplication_rate": 0-100,
  "skill": 0-5,
  "accuracy": 0-5,
  "eeat_summary": "<100å­—ä»¥å†…>",
  "improvement_advice": "<200å­—ä»¥å†…>"
}
"""

    with st.spinner("OpenAI ã§è©•ä¾¡ä¸­â€¦"):
        truncated_body = textwrap.shorten(body, 12000, placeholder="...[cut]...")
        user_msg = f"### è¨˜äº‹æœ¬æ–‡\n{truncated_body}\n\n### é¡ä¼¼ãƒšãƒ¼ã‚¸å€™è£œ\n" + "\n".join(similar_snips)

        chat = openai.ChatCompletion.create(
            model="gpt-4o-mini",
            temperature=0.1,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": user_msg}
            ]
        )
        result = json.loads(chat.choices[0].message.content)

    # â”€â”€â”€ 4. è¡¨ç¤º â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.subheader("è©•ä¾¡çµæœ")
    st.json(result, expanded=False)

    if result["pq"] in ["Lowest", "Low"]:
        st.error("âš ï¸ PQ ãŒä½è©•ä¾¡ã§ã™ã€‚ãƒªãƒ©ã‚¤ãƒˆæ¨å¥¨ â†’ æ”¹å–„ã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

    # â”€â”€â”€ 5. CSV ãƒ­ã‚°ä¿å­˜ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    log_row = {
        "timestamp": datetime.datetime.now().isoformat(timespec="seconds"),
        "source": src[:100],
        **result
    }
    pd.DataFrame([log_row]).to_csv("sqeg_log.csv", mode="a", index=False, header=not os.path.exists("sqeg_log.csv"))
    st.success("çµæœã‚’ sqeg_log.csv ã«è¿½è¨˜ã—ã¾ã—ãŸ âœ…")
